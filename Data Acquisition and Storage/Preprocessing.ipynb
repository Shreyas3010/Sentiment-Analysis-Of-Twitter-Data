{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This can be used for preprocessing of both sentiment analysis and categorical classification. \n",
    "\n",
    "#### Just change the necessary paths and parts of code for 2 different types of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import regex as re\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "\n",
    "FLAGS = re.MULTILINE | re.DOTALL\n",
    "\n",
    "def hashtag(text):\n",
    "    text = text.group()\n",
    "    hashtag_body = text[1:]\n",
    "    if hashtag_body.isupper():\n",
    "        result = \"<hashtag> {} <allcaps>\".format(hashtag_body.lower())\n",
    "    else:\n",
    "        result = \" \".join([\"<hashtag>\"] + re.split(r\"(?=[A-Z])\", hashtag_body, flags=FLAGS))\n",
    "    return result\n",
    "\n",
    "def allcaps(text):\n",
    "    text = text.group()\n",
    "    return text.lower() + \" <allcaps> \" # amackcrane added trailing space\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    # Different regex parts for smiley faces\n",
    "    eyes = r\"[8:=;]\"\n",
    "    nose = r\"['`\\-]?\"\n",
    "\n",
    "    # function so code less repetitive\n",
    "    def re_sub(pattern, repl):\n",
    "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \" <url> \")\n",
    "    text = re_sub(r\"@\\w+\", \" <user> \")\n",
    "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \" <smile> \")\n",
    "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \" <lolface> \")\n",
    "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \" <sadface> \")\n",
    "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \" <neutralface> \")\n",
    "    text = re_sub(r\"/\",\" / \")\n",
    "    text = re_sub(r\"<3\",\" <heart> \")\n",
    "    text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \" <number> \")\n",
    "    text = re_sub(r\"#\\w+\", hashtag)  # amackcrane edit\n",
    "    text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat> \")\n",
    "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong> \")\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    # amackcrane additions\n",
    "    text = re_sub(r\"([a-zA-Z<>()])([?!.:;,])\", r\"\\1 \\2\")\n",
    "    text = re_sub(r\"\\(([a-zA-Z<>]+)\\)\", r\"( \\1 )\")\n",
    "    text = re_sub(r\"  \", r\" \")\n",
    "    text = re_sub(r\" ([A-Z]){2,} \", allcaps)\n",
    "    \n",
    "    return text.lower()\n",
    "\n",
    "def is_allowed_specific_char(string):\n",
    "    charRe = re.compile(r'[^a-zA-Z@:\\\\]')\n",
    "    string = charRe.search(string)\n",
    "    return not bool(string)\n",
    "\n",
    "#_, text = sys.argv  # kaggle envt breaks this -amackcrane\n",
    "#if text == \"test\":\n",
    "text = \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\"\n",
    "text2 = \"'RT @nsg_ram: @GDGNITSurat @GoogleCloud #GoogleDevelopersGroup #Next17\\\\rWhat good is watching a movie without popcorn \\\\rAnd A Seminar with fooâ€¦'\" # couple extra tests -amackcrane\n",
    "tokens = tokenize(text)\n",
    "print(tokens)\n",
    "print(tokenize(text2).replace(\"\\\\r\",\"\").replace(\"'\",\"\").replace('\"',\"\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dfe27fcfc167>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### Give path for train_data.csv that you downloaded from Stanford site\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'drive/My Drive/trainingandtestdata/train_data.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin-1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "### Give path for train_data.csv that you downloaded from Stanford site\n",
    "\n",
    "dataset = pd.read_csv('drive/My Drive/trainingandtestdata/train_data.csv',encoding='latin-1')\n",
    "\n",
    "dataset = shuffle(dataset)\n",
    "print(dataset)\n",
    "\n",
    "\n",
    "\n",
    "dataset.columns = [\"polarity\",\"r1\",\"r2\",\"r3\",\"r4\",\"tweet\"]\n",
    "dataset = dataset.drop(columns = [\"r1\",\"r2\",\"r3\",\"r4\"])\n",
    "dataset=dataset\n",
    "print(dataset.info)\n",
    "\n",
    "\n",
    "\n",
    "tweets = dataset[\"tweet\"]\n",
    "tweets = np.array( tweets )\n",
    "n = len( tweets )\n",
    "print(n)\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(dataset.shape[0])):\n",
    "  tweets[i] = tokenize(tweets[i])\n",
    "  tweets[i] = re.sub(r\"[^'<>\\w\\s]\", \" \" , tweets[i])\n",
    "  tweets[i] = re.sub(r\"[']\", \"\" , tweets[i])\n",
    "  tweets[i] = ' '.join(tweets[i].split())\n",
    "    \n",
    "\n",
    "\n",
    "dataset['tweet'] = tweets\n",
    "dataset.insert(0, 'index', range(len(all_data)))\n",
    "print(dataset)\n",
    "\n",
    "\n",
    "'''\n",
    "Include below code for categorical classification dataset\n",
    "\n",
    "all_data[\"category\"] = all_data[\"category\"].replace(\"ENTERTAINMENT\",\"0\")\n",
    "all_data[\"category\"] = all_data[\"category\"].replace(\"POLITICS\",\"1\")\n",
    "all_data[\"category\"] = all_data[\"category\"].replace(\"SPORTS\",\"2\")\n",
    "all_data[\"category\"] = all_data[\"category\"].replace(\"BUSINESS\",\"3\")\n",
    "all_data[\"category\"] = all_data[\"category\"].replace(\"EDUCATION\",\"4\")\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "#### Give appropriate path ####\n",
    "#### Write \"polarity\" or \"category\" in as middle column as required ####\n",
    "\n",
    "\n",
    "dataset.to_csv('drive/My Drive/trainingandtestdata/glove_processed_data.csv', index=False, sep=\"|\", header=[\"index\",\"polarity\",\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
